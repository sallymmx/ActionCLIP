pretrain:  '/public/home/ock/video_clip/video-clip/clip_models/vit16_8f/model_best.pt'
resume:
seed: 1024
data:
    dataset: ucf101
    modality: RGB
    num_segments: 8
    seg_length: 1
    split: 1
    batch_size: 32
    workers: 8
    gpus: 2
    num_classes: 101
    image_tmpl: 'img_{:05d}.jpg'
    train_list: '/public/home/ock/video_clip/video-clip/lists/ucf101/train_rgb_split1.txt' 
    val_list: '/public/home/ock/video_clip/video-clip/lists/ucf101/val_rgb_split1.txt'
    label_list: 'lists/ucf_labels.csv'
    index_bias: 1
    input_size: 224
    randaug:
        N: 0 #2
        M: 0  #9
network:
    arch: CLIP-ViT-B/16  #CLIP-ViT-B/32 CLIP-ViT-B/16 TinyCLIP-ViT-61M/32-Text-29M TinyCLIP-ViT-40M/32-Text-19M
    init: True  
    drop_out: 0.0 
    emb_dropout: 0.0 
    type: clip_ucf
    sim_header: "Transf"  #Transf   meanP   LSTM   Transf_cls Conv_1D
    fix_text: False
    fix_img: False
    describe:
solver:
    type: cosine
    epochs: 50
    start_epoch: 0
    epoch_offset: 0
    optim: adamw
    lr: 5.e-6
    lr_warmup_step: 5
    momentum: 0.9
    weight_decay: 0.2
    lr_decay_step: 15
    lr_decay_factor: 0.1
    clip_gradient: 20
    loss_type: nll
    evaluate: False
    ratio: 1
    f_ratio: 10
logging:
    print_freq: 10
    eval_freq: 1